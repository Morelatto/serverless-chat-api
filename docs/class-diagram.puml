@startuml Chat API Class Diagram - Protocol-Based Architecture

' Color scheme definition
!define SERVICE_COLOR #4A90E2
!define PROTOCOL_COLOR #7FBA00
!define IMPLEMENTATION_COLOR #FF8C00
!define MODEL_COLOR #9B59B6
!define EXCEPTION_COLOR #E74C3C
!define TYPE_COLOR #34495E
!define CONFIG_COLOR #16A085

' Styling
skinparam classAttributeIconSize 0
skinparam class {
    BackgroundColor<<service>> SERVICE_COLOR
    BackgroundColor<<protocol>> PROTOCOL_COLOR
    BackgroundColor<<implementation>> IMPLEMENTATION_COLOR
    BackgroundColor<<model>> MODEL_COLOR
    BackgroundColor<<exception>> EXCEPTION_COLOR
    BackgroundColor<<typeddict>> TYPE_COLOR
    BackgroundColor<<dataclass>> CONFIG_COLOR
    BorderColor Black
    ArrowColor Black
}

' ===== MODELS (Pydantic) =====
class ChatMessage <<model>> {
    + user_id: str
    + content: str
    --
    + validate_user_id(value: str): str
    + validate_content(value: str): str
}

class ChatResponse <<model>> {
    + id: str
    + content: str
    + timestamp: datetime
    + cached: bool = False
    + model: str | None = None
}

' ===== SERVICES =====
class ChatService <<service>> {
    - repository: Repository
    - cache: Cache
    - llm_provider: LLMProvider
    --
    + __init__(repository, cache, llm_provider)
    + process_message(user_id: str, content: str): ChatResult
    + get_history(user_id: str, limit: int): list[MessageRecord]
    + health_check(): HealthStatus
}

' ===== PROTOCOLS =====
interface LLMProvider <<protocol>> {
    {abstract} + complete(prompt: str): LLMResponse
    {abstract} + health_check(): bool
}

interface Repository <<protocol>> {
    {abstract} + save(id, user_id, content, response, model, usage): None
    {abstract} + get_history(user_id: str, limit: int): list[MessageRecord]
    {abstract} + health_check(): bool
    {abstract} + startup(): None
    {abstract} + shutdown(): None
}

interface Cache <<protocol>> {
    {abstract} + get(key: str): dict | None
    {abstract} + set(key: str, value: dict, ttl: int = None): None
    {abstract} + startup(): None
    {abstract} + shutdown(): None
}

' ===== LLM IMPLEMENTATIONS =====
class GeminiProvider <<implementation>> {
    - config: LLMConfig
    - client: GenerativeModel
    --
    + __init__(config: LLMConfig)
    + complete(prompt: str): LLMResponse
    + health_check(): bool
    - _call_with_retry(prompt: str): LLMResponse
}

class OpenRouterProvider <<implementation>> {
    - config: LLMConfig
    --
    + __init__(config: LLMConfig)
    + complete(prompt: str): LLMResponse
    + health_check(): bool
    - _call_with_retry(prompt: str): LLMResponse
}

' ===== REPOSITORY IMPLEMENTATIONS =====
class SQLiteRepository <<implementation>> {
    - url: str
    - database: Database
    --
    + __init__(url: str)
    + save(id, user_id, content, response, model, usage): None
    + get_history(user_id: str, limit: int): list[MessageRecord]
    + health_check(): bool
    + startup(): None
    + shutdown(): None
    - _ensure_table(): None
}

class DynamoDBRepository <<implementation>> {
    - table_name: str
    - region: str
    - session: ClientSession
    - dynamodb: DynamoDBServiceResource
    --
    + __init__(table_name: str, region: str)
    + save(id, user_id, content, response, model, usage): None
    + get_history(user_id: str, limit: int): list[MessageRecord]
    + health_check(): bool
    + startup(): None
    + shutdown(): None
    - _ensure_table(): None
}

' ===== CACHE IMPLEMENTATIONS =====
class InMemoryCache <<implementation>> {
    - cache: dict
    - ttl: int
    --
    + __init__(ttl: int = 3600)
    + get(key: str): dict | None
    + set(key: str, value: dict, ttl: int = None): None
    + startup(): None
    + shutdown(): None
    - _is_expired(timestamp: float): bool
}

class RedisCache <<implementation>> {
    - url: str
    - ttl: int
    - redis: Redis
    --
    + __init__(url: str, ttl: int = 3600)
    + get(key: str): dict | None
    + set(key: str, value: dict, ttl: int = None): None
    + startup(): None
    + shutdown(): None
}

' ===== DATA CLASSES =====
class LLMConfig <<dataclass>> {
    + model: str
    + api_key: str
    + timeout: int = 30
    + temperature: float = 0.7
    + max_tokens: int = 1000
}

class LLMResponse <<dataclass>> {
    + text: str
    + model: str
    + usage: dict[str, Any]
}

' ===== TYPED DICTS =====
class TokenUsage <<typeddict>> {
    + prompt_tokens: int
    + completion_tokens: int
    + total_tokens: int
    + cost_usd: float
}

class HealthStatus <<typeddict>> {
    + storage: bool
    + llm: bool
}

class ChatResult <<typeddict>> {
    + id: str
    + content: str
    + model: str
    + cached: bool
    + usage: dict
}

class MessageRecord <<typeddict>> {
    + id: str
    + user_id: str
    + content: str
    + response: str
    + model: str
    + timestamp: str
    + usage: dict
}

' ===== EXCEPTIONS =====
class ChatAPIError <<exception>> {
    {abstract}
}

class LLMProviderError <<exception>> {
}

class StorageError <<exception>> {
}

class ValidationError <<exception>> {
}

class ConfigurationError <<exception>> {
}

' ===== RELATIONSHIPS =====

' Service dependencies (composition)
ChatService o-- LLMProvider : uses
ChatService o-- Repository : uses
ChatService o-- Cache : uses

' Protocol implementations
GeminiProvider ..|> LLMProvider : implements
OpenRouterProvider ..|> LLMProvider : implements

SQLiteRepository ..|> Repository : implements
DynamoDBRepository ..|> Repository : implements

InMemoryCache ..|> Cache : implements
RedisCache ..|> Cache : implements

' Data class usage
GeminiProvider --> LLMConfig : uses
OpenRouterProvider --> LLMConfig : uses
GeminiProvider --> LLMResponse : returns
OpenRouterProvider --> LLMResponse : returns

' Model usage
ChatService --> ChatMessage : processes
ChatService --> ChatResponse : creates
ChatService --> ChatResult : returns
ChatService --> MessageRecord : returns
ChatService --> HealthStatus : returns

' TypedDict relationships
LLMResponse --> TokenUsage : contains
ChatResult --> TokenUsage : contains
MessageRecord --> TokenUsage : contains

' Exception hierarchy
LLMProviderError --|> ChatAPIError : extends
StorageError --|> ChatAPIError : extends
ValidationError --|> ChatAPIError : extends
ConfigurationError --|> ChatAPIError : extends

' Exception usage
ChatService ..> LLMProviderError : throws
ChatService ..> StorageError : throws
Repository ..> StorageError : may throw
LLMProvider ..> LLMProviderError : may throw

' Notes
note right of ChatService
  Core service using dependency injection
  All dependencies are protocols
  enabling easy testing and swapping
end note

note left of LLMProvider
  Protocol defining contract
  for LLM providers
end note

note bottom of TokenUsage
  TypedDicts provide
  structured typing for
  dictionary-based data
end note

note right of ChatAPIError
  Simple exception hierarchy
  following YAGNI principle
end note

@enduml
