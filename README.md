# API de Chat Serverless

[![CI](https://github.com/Morelatto/AWSDeployTest/actions/workflows/ci.yml/badge.svg)](https://github.com/Morelatto/AWSDeployTest/actions/workflows/ci.yml)
[![Deploy](https://github.com/Morelatto/AWSDeployTest/actions/workflows/deploy.yml/badge.svg)](https://github.com/Morelatto/AWSDeployTest/actions/workflows/deploy.yml)
[![MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

API serverless multi-LLM em container Docker no AWS Lambda, com suporte a OpenRouter/Gemini, DynamoDB e deploy autom√°tico via GitHub Actions.

## In√≠cio R√°pido

```bash
# Setup
git clone https://github.com/Morelatto/AWSDeployTest.git
cd AWSDeployTest && make dev
cp .env.example .env  # Configure suas API keys

# Executar
python -m src.main     # Local
make docker-env        # Docker

# Testar
curl localhost:8000/v1/health
curl -X POST localhost:8000/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"userId": "user123", "prompt": "Ol√°!"}'
```

## Configura√ß√£o

### LLM Providers (Uma das op√ß√µes abaixo)
- `OPENROUTER_API_KEY` - Para usar OpenRouter (recomendado)
- `GEMINI_API_KEY` - Para usar Google Gemini diretamente
- `LLM_PROVIDER` - `openrouter` | `gemini` | `mock` (auto-detectado)

### Database
- **Local**: SQLite (`DATABASE_PATH` - default: `chat_history.db`)
- **Produ√ß√£o**: DynamoDB com `interaction_id` como chave prim√°ria
- `TABLE_NAME` ou `DYNAMODB_TABLE` - Nome da tabela DynamoDB

### Seguran√ßa
- `REQUIRE_API_KEY` - Habilitar autentica√ß√£o (default: `false`)
- `API_KEY` ou `API_KEYS` - Chaves de API v√°lidas
- `RATE_LIMIT_PER_MINUTE` - Default: 60

## API

**Documenta√ß√£o interativa dispon√≠vel em `/docs` (Swagger) e `/redoc`**

### `POST /v1/chat`
```json
// Request
{"userId": "string", "prompt": "string"}

// Response
{
  "interaction_id": "uuid",
  "userId": "string",
  "prompt": "string",
  "response": "string",
  "model": "string",
  "timestamp": "ISO-8601"
}
```

### `GET /v1/health`
Retorna status, vers√£o e timestamp.

## Deploy

### Arquitetura

```mermaid
graph TB
    %% Estilo minimalista monocrom√°tico
    classDef node fill:#fff,stroke:#374151,stroke-width:2px,color:#374151
    classDef focus fill:#374151,stroke:#374151,stroke-width:2px,color:#fff
    classDef external fill:#fff,stroke:#374151,stroke-width:2px,stroke-dasharray:5 5,color:#374151

    %% Arquitetura
    Client(Cliente):::node
    Gateway(API Gateway):::node
    Lambda(Lambda Function):::focus
    DB[(DynamoDB)]:::node
    LLM(LLM Providers<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ<br/>Gemini & OpenRouter):::external

    %% Conex√µes
    Client --> Gateway
    Gateway --> Lambda
    Lambda --> DB
    Lambda --> LLM

    %% Contexto AWS
    subgraph cloud[AWS Cloud]
        Gateway
        Lambda
        DB
    end

    style cloud fill:#f9fafb,stroke:#d1d5db,stroke-width:1px
```

### Componentes
- **Lambda com Container Images**: Supera limite de 250MB das layers tradicionais
- **ECR**: Armazenamento de imagens Docker (at√© 10GB)
- **DynamoDB**: Persist√™ncia serverless com Global Secondary Index
- **GitHub Actions**: CI/CD autom√°tico em push para `main`

### Deploy Manual
```bash
# Via Terraform
cd iac/terraform
terraform init
terraform apply

# Build e push Docker
aws ecr get-login-password | docker login --username AWS --password-stdin [ECR_URL]
docker build --build-arg TARGET=lambda -t serverless-chat-api .
docker tag serverless-chat-api:latest [ECR_URL]:latest
docker push [ECR_URL]:latest
```

### Deploy Autom√°tico
Push para `main` executa:
1. Testes e linting
2. Build da imagem Docker
3. Push para ECR
4. Deploy do Lambda via Terraform
5. Teste de sa√∫de do endpoint

## Performance
- **Lat√™ncia**: < 200ms p50, < 500ms p99 (cold start ~1-2s com container)
- **Concorr√™ncia**: 1000 execu√ß√µes simult√¢neas
- **Mem√≥ria**: 512MB configur√°vel
- **Timeout**: 30s configur√°vel
- **Custo estimado**: ~$0.20/milh√£o requisi√ß√µes + ECR storage

## Desenvolvimento

### Estrutura do Projeto
```
serverless-chat-api/
‚îú‚îÄ‚îÄ src/                    # C√≥digo fonte
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # FastAPI app com Mangum handler
‚îÇ   ‚îú‚îÄ‚îÄ routes/            # Endpoints da API
‚îÇ   ‚îî‚îÄ‚îÄ shared/            # Config, database, LLM providers
‚îú‚îÄ‚îÄ iac/terraform/         # Infraestrutura como c√≥digo
‚îú‚îÄ‚îÄ tests/                 # 98 testes com 91% cobertura
‚îú‚îÄ‚îÄ Dockerfile            # Multi-stage para local e Lambda
‚îî‚îÄ‚îÄ pyproject.toml        # Depend√™ncias e configura√ß√£o
```

### Comandos
```bash
pytest tests/              # Executa todos os 98 testes
pytest tests/ --cov=src    # Com relat√≥rio de cobertura (91%)
ruff check src/           # Linting e formata√ß√£o
make docker-env           # Desenvolvimento local com Docker
```

## ü§ù Contribuindo

1. Fa√ßa um fork do reposit√≥rio
2. Crie sua branch de feature (`git checkout -b feature/recurso-incrivel`)
3. Fa√ßa commit das suas mudan√ßas (`git commit -m 'Adiciona recurso incr√≠vel'`)
4. Fa√ßa push para a branch (`git push origin feature/recurso-incrivel`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.
