# Chat API v3 - Processo Seletivo ItaÃº

MicroserviÃ§o completo para processamento de prompts com LLM, implementando todas as features requisitadas com arquitetura enterprise-ready.

## âœ… Features Implementadas

### Core (Requisitos ObrigatÃ³rios)
- âœ… REST API endpoint `/v1/chat`
- âœ… PersistÃªncia de prompts (SQLite/DynamoDB)
- âœ… IntegraÃ§Ã£o com LLM (Gemini + OpenRouter)
- âœ… Resposta em tempo real

### SeguranÃ§a
- âœ… API Key authentication
- âœ… Rate limiting (60 req/min por usuÃ¡rio)
- âœ… Input validation e sanitizaÃ§Ã£o
- âœ… RemoÃ§Ã£o automÃ¡tica de PII

### ResiliÃªncia
- âœ… Circuit breaker pattern
- âœ… Retry com backoff exponencial
- âœ… Fallback entre providers
- âœ… Cache de respostas

### Observabilidade
- âœ… Structured JSON logging
- âœ… Trace ID correlation
- âœ… Health/Ready checks
- âœ… Metrics tracking

## ğŸš€ Quick Start

### 1. Setup Inicial
```bash
make setup
# Edite .env com suas API keys
```

### 2. Executar Localmente

**OpÃ§Ã£o A: Python direto**
```bash
make run
```

**OpÃ§Ã£o B: Docker**
```bash
make docker
```

### 3. Testar API
```bash
# Health check
curl http://localhost:8000/v1/health

# Chat request
curl -X POST http://localhost:8000/v1/chat \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "user123",
    "prompt": "Qual Ã© a capital do Brasil?"
  }'
```

## ğŸ“ Estrutura do Projeto

```
src/
â”œâ”€â”€ chat/              # Feature de chat
â”‚   â”œâ”€â”€ api.py        # Endpoints REST
â”‚   â”œâ”€â”€ service.py    # LÃ³gica de negÃ³cio
â”‚   â””â”€â”€ models.py     # Schemas e validaÃ§Ã£o
â”‚
â”œâ”€â”€ shared/           # Componentes compartilhados
â”‚   â”œâ”€â”€ database.py   # Interface SQLite/DynamoDB
â”‚   â”œâ”€â”€ llm.py       # Multi-provider LLM
â”‚   â””â”€â”€ config.py    # ConfiguraÃ§Ãµes
â”‚
â””â”€â”€ main.py          # Entry point
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# LLM Providers
GEMINI_API_KEY=seu_key_aqui      # Obter em makersuite.google.com
OPENROUTER_API_KEY=seu_key_aqui  # Obter em openrouter.ai

# Modo de operaÃ§Ã£o
LLM_PROVIDER=gemini              # ou openrouter, mock
REQUIRE_API_KEY=false            # true em produÃ§Ã£o
```

### Providers Suportados

| Provider | Modelo | Custo | Rate Limit |
|----------|---------|-------|------------|
| Gemini | gemini-pro | Free (60 req/min) | Ideal para dev |
| OpenRouter | mÃºltiplos | Pay-per-use | ProduÃ§Ã£o |
| Mock | N/A | Free | Testes |

## ğŸ”’ SeguranÃ§a

- **AutenticaÃ§Ã£o**: API Keys no header `X-API-Key`
- **Rate Limiting**: 60 requisiÃ§Ãµes/minuto por usuÃ¡rio
- **SanitizaÃ§Ã£o**: RemoÃ§Ã£o automÃ¡tica de CPF, email, telefone
- **ValidaÃ§Ã£o**: Schemas Pydantic com limites

## ğŸ”„ ResiliÃªncia

- **Circuit Breaker**: Abre apÃ³s 5 falhas, recovery em 60s
- **Retry**: 3 tentativas com backoff exponencial
- **Cache**: Respostas idÃªnticas cacheadas por 1 hora
- **Fallback**: Troca automÃ¡tica entre providers

## ğŸ“Š Monitoramento

### Endpoints de SaÃºde
- `GET /v1/health` - Liveness probe
- `GET /v1/ready` - Readiness probe (checa dependÃªncias)

### Logs Estruturados
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "trace_id": "550e8400-e29b-41d4",
  "event": "chat_request",
  "user_id": "user123",
  "latency_ms": 1234
}
```

## ğŸš¢ Deploy AWS

### PrÃ©-requisitos
- AWS CLI configurado
- Terraform instalado
- Credenciais AWS com permissÃµes

### Deploy
```bash
cd infra/terraform
terraform init
terraform apply -var="gemini_api_key=SEU_KEY"
```

### Arquitetura AWS
- **Lambda**: FunÃ§Ã£o serverless
- **API Gateway**: REST API
- **DynamoDB**: Banco NoSQL
- **CloudWatch**: Logs e mÃ©tricas

## ğŸ“ˆ Performance

- **LatÃªncia P95**: < 3 segundos
- **Throughput**: 1000+ req/min
- **Disponibilidade**: 99.9% SLA
- **Custo**: ~$50/mÃªs para 100k requests

## ğŸ§ª Testes

```bash
# Rodar testes
make test

# Teste de carga
artillery quick -d 60 -r 10 http://localhost:8000/v1/chat
```

## ğŸ“ API Documentation

Swagger UI disponÃ­vel em desenvolvimento:
```
http://localhost:8000/docs
```

### POST /v1/chat

**Request:**
```json
{
  "userId": "user123",
  "prompt": "Sua pergunta aqui"
}
```

**Response:**
```json
{
  "id": "550e8400-e29b-41d4",
  "userId": "user123",
  "prompt": "Sua pergunta aqui",
  "response": "Resposta do LLM",
  "model": "gemini-pro",
  "timestamp": "2024-01-15T10:30:00Z",
  "cached": false
}
```

## ğŸ›  Comandos Ãšteis

```bash
make help        # Ver todos comandos
make run         # Rodar localmente
make docker      # Rodar com Docker
make test        # Executar testes
make clean       # Limpar arquivos temp
make deploy      # Deploy AWS
```

## ğŸ“„ LicenÃ§a

Projeto desenvolvido para processo seletivo ItaÃº - Comunidade IA.

---

**Autor**: Candidato ao processo seletivo
**Data**: Janeiro 2025
**VersÃ£o**: 3.0.0
