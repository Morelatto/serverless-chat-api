# API de Chat Serverless

[![CI](https://github.com/Morelatto/AWSDeployTest/actions/workflows/ci.yml/badge.svg)](https://github.com/Morelatto/AWSDeployTest/actions/workflows/ci.yml)
[![Deploy](https://github.com/Morelatto/AWSDeployTest/actions/workflows/deploy.yml/badge.svg)](https://github.com/Morelatto/AWSDeployTest/actions/workflows/deploy.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

API serverless pronta para produ√ß√£o com suporte a m√∫ltiplos LLMs, otimizada para AWS Lambda.

## üéØ Principais Funcionalidades

- **Suporte Multi-LLM** - Gemini, OpenRouter com fallback autom√°tico
- **Serverless** - Otimizada para AWS Lambda/API Gateway
- **N√≠vel Empresarial** - Circuit breakers, rate limiting, rastreamento distribu√≠do
- **Banco de Dados Flex√≠vel** - SQLite (desenvolvimento), DynamoDB (produ√ß√£o)
- **Totalmente Testada** - 95%+ de cobertura, testes E2E, carga e resili√™ncia

## üöÄ In√≠cio R√°pido

### Desenvolvimento Local

```bash
# Clonar e configurar
git clone https://github.com/Morelatto/AWSDeployTest.git
cd AWSDeployTest
make setup

# Configurar ambiente
cp .env.example .env
# Edite o .env com suas chaves de API

# Executar localmente
make run
# ou com Docker
make docker
```

### Testar a API

```bash
# Verifica√ß√£o de sa√∫de
curl http://localhost:8000/v1/health

# Enviar requisi√ß√£o de chat
curl -X POST http://localhost:8000/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"userId": "user123", "prompt": "Ol√°, mundo!"}'
```

## üì¶ Instala√ß√£o

### Usando pip
```bash
pip install -e .
```

### Usando uv (recomendado)
```bash
uv pip install -e .
```

### Usando Docker
```bash
docker build -t serverless-chat-api .
docker run -p 8000:8000 --env-file .env serverless-chat-api
```

## üèóÔ∏è Arquitetura

```mermaid
graph LR
    Cliente[Cliente] --> Gateway[API Gateway]
    Gateway --> Lambda[AWS Lambda]
    
    Lambda --> DynamoDB[(DynamoDB)]
    Lambda --> Gemini[Gemini API]
    Lambda --> OpenRouter[OpenRouter API]
    
    subgraph AWS
        Gateway
        Lambda
        DynamoDB
    end
    
    subgraph LLM Providers
        Gemini
        OpenRouter
    end
    
    style Cliente fill:#e1f5fe
    style Gateway fill:#fff3e0
    style Lambda fill:#f3e5f5
    style DynamoDB fill:#e8f5e9
    style Gemini fill:#fce4ec
    style OpenRouter fill:#fce4ec
```

## üõ†Ô∏è Configura√ß√£o

### Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Padr√£o | Obrigat√≥rio |
|----------|-----------|--------|-------------|
| `GEMINI_API_KEY` | Chave da API do Google Gemini | - | Sim |
| `OPENROUTER_API_KEY` | Chave da API do OpenRouter | - | N√£o |
| `LLM_PROVIDER` | Provedor LLM principal | `gemini` | N√£o |
| `DATABASE_TYPE` | Tipo de banco de dados | `sqlite` | N√£o |
| `LOG_LEVEL` | N√≠vel de log | `INFO` | N√£o |
| `REQUIRE_API_KEY` | Habilitar autentica√ß√£o por API key | `false` | N√£o |

### Provedores LLM Suportados

| Provedor | Modelos | Pre√ßo | Melhor Para |
|----------|---------|-------|-------------|
| **Gemini** | gemini-pro, gemini-flash | Gratuito: 60 RPM | Desenvolvimento, baixo volume |
| **OpenRouter** | 100+ modelos | Pago por token | Produ√ß√£o, alto volume |
| **Mock** | Respostas de teste | Gratuito | Testes, CI/CD |

## üß™ Testes

```bash
# Executar todos os testes
make test

# Executar com cobertura
make test-coverage

# Executar su√≠tes espec√≠ficas
pytest tests/unit/
pytest tests/integration/
pytest tests/e2e/
```

## üìä Performance

- **Lat√™ncia**: < 200ms p50, < 500ms p99
- **Taxa de Transfer√™ncia**: 10.000+ requisi√ß√µes/seg
- **Disponibilidade**: 99.9% SLA
- **Custo**: < R$250 por milh√£o de requisi√ß√µes

## üö¢ Deploy

### AWS Lambda

```bash
# Deploy para desenvolvimento
make deploy-dev

# Deploy para produ√ß√£o
make deploy-prod
```

### Terraform

```bash
cd iac/terraform
terraform init
terraform apply
```

### GitHub Actions

Deploy automatizado ao fazer push para a branch `main`. Veja `.github/workflows/deploy.yml`.

## üìñ Documenta√ß√£o da API

### POST /v1/chat

Envia uma mensagem de chat para o LLM.

**Requisi√ß√£o:**
```json
{
  "userId": "string",
  "prompt": "string"
}
```

**Resposta:**
```json
{
  "id": "uuid",
  "userId": "string",
  "prompt": "string",
  "response": "string",
  "model": "string",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

### GET /v1/health

Endpoint de verifica√ß√£o de sa√∫de.

**Resposta:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

## ü§ù Contribuindo

1. Fa√ßa um fork do reposit√≥rio
2. Crie sua branch de feature (`git checkout -b feature/recurso-incrivel`)
3. Fa√ßa commit das suas mudan√ßas (`git commit -m 'Adiciona recurso incr√≠vel'`)
4. Fa√ßa push para a branch (`git push origin feature/recurso-incrivel`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üîó Links

- [Documenta√ß√£o](https://morelatto.github.io/AWSDeployTest/)
- [Issues](https://github.com/Morelatto/AWSDeployTest/issues)
- [Discuss√µes](https://github.com/Morelatto/AWSDeployTest/discussions)

## üôè Agradecimentos

Constru√≠do com FastAPI, AWS Lambda e amor pela arquitetura serverless.